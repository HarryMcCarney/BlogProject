{
  "Posts": [
    {
      "FileName": "10RulesForDistributedAgile",
      "Title": "10 rules for Distributed Agile — How H&C gets stuff done.",
      "Summary": "H&C has been working from home since before it became synonymous with flattening the curve. Many companies have previously allowed employees to work from home but the need for complex systems to be built by teams of people who don’t ever physically meet is a new challenge. Hopefully this account of how H&C does this will demonstrate that Distributed Agile is not only possible, but actually more efficient than co-located teams.",
      "Content": "\r\n<h2>How we got here</h2>\r\n<p>Initially, this way of working was driven by H&amp;C’s need to hire top notch engineers. As our Berlin office filled, we realised we needed more space. At this time in Berlin there was also a large influx of venture capital into new startups which created huge competition for the best developers. In response to this we opened an office in Barcelona and began hiring developers, effectively splitting the product teams across two locations.</p>\r\n<p>Unfortunately, we quickly realised that crucial communication gets lost in split location product and engineering teams. Subtle but critical decisions were made in the physical coffee meetings and subsequently lost in the sometimes chaotic video conferences between two packed and echoey meeting rooms. We began thinking there must be a better way.</p>\r\n<p>We were also greatly influenced by <a href=\"https://www.joelonsoftware.com/2006/09/07/a-field-guide-to-developers-2/\">this</a> Joel Spolsky Essay. He argues that all developers and knowledge workers doing <a href=\"https://suebehaviouraldesign.com/kahneman-fast-slow-thinking/\">‘System 2’ thinking</a>, as defined by Nobel prize winning psychologist Daniel Kahneman, should have their own single person office. We realised we could address this, improve channels of communication, and access a wider pool of talent around the world by transferring everyone to home working.</p>\r\n<p><img src=\"/berlin.png\" alt=\"Berlin and London\" /></p>\r\n<hr />\r\n<h2>10 rules for effective Distributed Agile working</h2>\r\n<p>From this point on we built the methodology and working practises necessary to make our distributed team exceptionally productive. This established H&amp;C’s now industry-wide reputation for high-quality complex innovation at pace. Here are our top 10 rules of effective distributed agile working. They definitely work for us and I hope they are useful for you.</p>\r\n<h4>1.  Take an all or nothing approach</h4>\r\n<p>Most of us have had the experience of joining a conference in which all the other participants are sitting in the room together. In these situations it is incredibly difficult to understand what is being agreed as the participants in the room are using communication styles suited to physical f2f meetings which do not transmit clearly over the wire to remote participants.</p>\r\n<p>When everyone ‘dials in’ the communication style changes so that everyone can contribute. To enable this to work properly, H&amp;C insisted early on that everyone should work from home. We’ve even recreated the same ‘working from home’ environment in our newly renovated UK office in order to preserve this high-resolution communication.</p>\r\n<h4>2. Distributed working does not equal flexitime</h4>\r\n<p>When people learn we are a distributed company, it’s often assumed that we work with flexitime. In fact, the opposite is true. Because we don’t share space it’s extra important that we share time. We start every day at 8am (yes, this means we don’t hire people with more than a three-hour time zone difference from the UK) with a check-in video conference with everyone in the company. We then split up into parallel conferences for each project.</p>\r\n<p>Everyone is then available throughout the day via <a href=\"https://slack.com/intl/en-gb/?eu_nc=1\">slack</a> and spontaneous hangouts. Our projects require constant real time collaboration and working from home makes this easier due to our constant connectivity. Our teams are always ready to join face-to-face virtual meetings. Traditional offices often rely on emails which are slow and asynchronous and getting people to gather up their clobber and trundle along to a meeting room wastes more time. At H&amp;C we work in true real time.</p>\r\n<h4>3. You can now hire the best</h4>\r\n<p>Perhaps the greatest advantage of distributed teams is the freedom to set very high standards for new recruits. Hiring talent across four time zones means access to a wide pool of the very best talent. For us, removing restrictions surrounding recruiting only from a small pool of scarce talent within commutable reach of the office has been hugely beneficial. Perhaps one good thing that will emerge from the current situation is that it will encourage traditional companies to adopt distributed working practices, and by extension give them the opportunity to hire world-class talent.</p>\r\n<h4>4. Always use a camera</h4>\r\n<p>Distributed working doesn’t work if people can’t see each other’s faces. The effectiveness of communication increases tenfold when people use cameras. Many companies are up to speed with Skype for business, but don’t use cameras. As a result, people struggle to clearly communicate on complex or sensitive topics.</p>\r\n<h4>5. Buy a top-quality microphone</h4>\r\n<p>It’s hard to overstate the importance of good quality audio equipment. If people are struggling to hear you, they will become tired and irritable and crucial information could be lost. I’d advise using our go-to solution, the Jabra Speak 510, which we buy for all new staff and freelancers. Invest in a headset and notice how much keener people are to talk to you.</p>\r\n<h4>6. Write a summary at the end of each day</h4>\r\n<p>At the end of each day, our staff send a short email to all members of their team. They include what they did that day, and what they hope to do the next day. This ensures everyone remains in sync. It also marks the end of the day, which is helpful psychologically and is similar to the effect of saying goodbye and leaving the office. It’s also useful preparation for team leads to prepare for the Stand-up meetings the following day.</p>\r\n<h4>7. Be spontaneous and hold micro meetings when you need them</h4>\r\n<p>Organising and holding traditional face-to-face meetings in a physical office space is a notorious time sink. From the availability of meeting rooms to ensuring everyone attends, meetings are difficult to keep under half an hour. In practice, we rarely find decisions can’t be made in less than 30 minutes and cutting out this whole process saves a vast amount of time.\r\nIn our distributed team, we hold many very short and spontaneous virtual meetings throughout the day. Each project or workstream has a dedicated slack channel with a static Google Meet URL pinned inside. A team member only needs to invite colleagues into the virtual meeting and the whole team can communicate face-to-face in seconds with no fuss. They can then return to their work equally seamlessly.</p>\r\n<h4>8. Write down action points in real time during the meeting</h4>\r\n<p>In a traditional physical meeting one person is asked to take minutes. They will generally do this on a pad or in their laptop and then circulate the meeting minutes via email after the meeting. This is a very leaky way to record agreements and often leads to misunderstandings and lack of follow through. Video conferencing enables you to share screens, even better share a google doc, which all the meeting attendees can edit and comment on during the meeting.\r\nAs the discussion proceeds, participants can see the consensus being recorded. Any concerns about phrasing, validity, edits and additions can be raised and sorted then. In this way the minutes are written and agreed as the meeting progresses. This enables a clear unambiguous conclusion and the possibility to begin implementing the agreed actions while the topic is still fresh and the team has momentum.</p>\r\n<h4>9. Always share your screen</h4>\r\n<p>It’s vital for distributed teams using video conferencing. Most meetings will focus on a document, whether that’s excel or a code file. To get the most out of the conversation, everyone needs to have eyes on the subject. A screen share is the easiest way to do this.</p>\r\n<h4>10. Remember that purpose creates trust.</h4>\r\n<p>Ultimately distributed working has worked very well for H&amp;C because we created a common sense of purpose. The whole company is united in our desire to create the highest quality technology solutions for the most complex problems in manufacturing and industry. We do this by creating an environment that minimises obstructions to the engineers and product designers who produce the real value. This shared sense of purpose is what creates trust, which is the essential ingredient to making distributed work productive.</p>\r\n<hr />\r\n<p>I hope this proves useful to organisations currently adapting to remote collaborative working. When COVID-19 is behind us, those organisations that embrace distributed working will come out stronger.</p>\r\n\r\n",
      "Tags": [
        "Agile",
        "H&C",
        "Software Engineering",
        "Teams"
      ],
      "Category": "Essay",
      "Updated": "2020-04-09T00:00:00.0000000",
      "Created": "2020-04-09T00:00:00.0000000"
    },
    {
      "FileName": "MontyHall",
      "Title": "Bayesian F# Series - The Monty Hall Paradox.",
      "Summary": "This is the first in a series of posts exploring how Bayesian Techniques can be implemented in F#. It will also provide simple examples of how to started using Plotly.NET and FSharp.stats.",
      "Content": "\r\n<h1>Introduction</h1>\r\n<p>The posts will closely follow Allen Downey's excellent book Think Bayes. Each post will cover one or two chapters from his book summarising the key ideas and porting the examples to F#. The first few posts will hopefully be quite accessible and the complexity will increase as we progress though the book.</p>\r\n<p>The goal is that any one with some knowledge of F# will be able to implement the Bayesian techniques covered in the real world.</p>\r\n<h1>Why F#</h1>\r\n<p>F# is an excellent language for Data Science. The rich static type system guides your thinking while you structure solutions to problems. It avoids the 'guess/refresh' approach sometimes found with loosely typed languages. Moreover, the extra precision of types that won't let you multiply strings, concatenate a boolean, or add an int to a float ensures your code is correct.</p>\r\n<p>Lastly, functional immutable programming is simply a better conceptual fit for most data science work. Object oriented languages are primarily about managing state, not transforming data. F#’s functional first approach encourages us to write simple deterministic functions which are easy to understand and compose into larger and larger operations with no loss of readability.</p>\r\n<h1>Data Science at Hack and Craft</h1>\r\n<p>At Hack and Craft we build simulations for logistics and manufacturing companies. Typically they are interested in measuring the effects of proposed chances to their processes. We model these initiatives and run simulations to produce synthetic data. This data is then analysed to measure impact of the proposed changes.</p>\r\n<p>We find Bayesian approaches very applicable to this work and have gradually moved away from a more traditional 'frequentist' approach.</p>\r\n<h1>Bayesian thinking</h1>\r\n<p>Frequentist techniques use ratios between the frequencies of possible cases of an observed sequence of data to derive their probability.</p>\r\n<p>So the probability of a coin landing on heads is established by looking at a sequence of flips. Such as T, H, T, T, T, T, H, T, T, H, H, T. In this sequence there are 4 Heads and 8 Tails. SO the probability of Heads is 4/12 or 0.33. This conclusion feels wrong as we know that coins are normally evenly weighted and our conclusion that this is an uneven coin is based on a short sequence of data.</p>\r\n<p>In the real world H&amp;C's clients often have partial and noisy data. And they nearly alway have some preexisting beliefs which should guide our analysis.</p>\r\n<p>This is where Bayesian techniques can help. Instead of trying to calculate the probability of heads from the data, the Bayesian asks, given this data what the probability that this is a 50/50 coin. They can also ask what the probability that this is 33$ coin or a 66% coin.</p>\r\n<p>These three coins represent three different hypotheses which are equally likely before we see the sequence of flips but not equally likely afterwards. Given that only 4/12 flips return heads we can infer that its now more likely that we have 33% coins than a 66% coin.</p>\r\n<p>In this way our probability of having each coin can be updated using the observed data.</p>\r\n<p>The formula for calculating this is known as Bayes Theorem. Its a complex theorem but the core idea is quite intuitive. Data allows us to update the probabilities of our competing beliefs. These beliefs are held with varying levels of certainty before we make observations and afterwards we change those convictions. This series of article will explore a variety of increasingly and sometimes complex but always practical applications of this approach.</p>\r\n<h1>A Bayesian approach to the Monty Hall paradox</h1>\r\n<p>The Monty Hall Paradox is a well known probability puzzle which many people find intuitively challenging. It has divided opinion even among experts. Bayesian thinking makes this puzzle much more tractable than traditional frequentist so its a an excellent place to start.</p>\r\n<p>The puzzle is as follows: Imagine a game show. The host is called Monty. There are three doors. Behind one of the doors is a car which the contestant is trying to win. A contestant is asked to to choose a door. Then Monty opens one of the other two doors which doesn't have the car behind it. This leaves two doors left and the car is behind one of them. Monty then asks the contestant if they would like to stick with their original choice or switch to the other door. Most people will assume there is a 50/50 chance for both doors so there is nothing to be gain from switching. However, switching doors is a the better choice and raises the odds of winning to 2/3</p>\r\n<p>Its hard to explain this with frequentist theory but a Bayesisn phrasing of the puzzle makes it intuitively clear that the contestant should switch.</p>\r\n<p>But first for anyone skeptical about why the contestant should switch, which I was, heres empirical proof. The code below simulates the game 10k times. 5k with a switch strategy and 5k with a non switching strategy. THe graph shows the switcher wins almost exactly 66.6% of the time, while the non-switcher's odds remain on 33.3%. Later we will show how we can derive the same results analytically using Bayes rule.</p>\r\n<h1>r \"nuget: Plotly.NET.Interactive, 4.0.0\"</h1>\r\n<p>Installed Packages\r\nPlotly.NET.Interactive, 4.0.0\r\nLoading extensions from <code>C:\\Users\\harry\\.nuget\\packages\\plotly.net.interactive\\4.0.0\\interactive-extensions\\dotnet\\Plotly.NET.Interactive.dll</code>\r\nopen System\r\nopen Plotly.NET</p>\r\n<p>//Helpers\r\nlet rnd from until = Random().Next(from, until)</p>\r\n<p>let rec rndExclude from until (excl: int list) =\r\nlet r = rnd from until</p>\r\n<pre class=\"fssnip highlighted\"><code lang=\"fsharp\"><span class=\"k\">if</span> <span class=\"id\">excl</span> <span class=\"o\">|&gt;</span> <span onmouseout=\"hideTip(event, '1', 1)\" onmouseover=\"showTip(event, '1', 1)\" class=\"m\">List</span><span class=\"pn\">.</span><span onmouseout=\"hideTip(event, '2', 2)\" onmouseover=\"showTip(event, '2', 2)\" class=\"id\">contains</span> <span class=\"id\">r</span> <span class=\"k\">then</span>\r\n    <span class=\"id\">rndExclude</span> <span class=\"id\">from</span> <span class=\"id\">until</span> <span class=\"id\">excl</span>\r\n<span class=\"k\">else</span>\r\n    <span class=\"id\">r</span>\r\n</code></pre>\r\n<p>//Domain\r\ntype Player =\r\n| Switcher\r\n| NonSwitcher</p>\r\n<p>type Door =\r\n| Door1\r\n| Door2\r\n| Door3</p>\r\n<p>type Game =\r\n{ Player: Player\r\nCarLocation: Door\r\nPlayersFirstChoice: Door option\r\nMontyRevealed: Door option\r\nPlayersFinalChoice: Door option\r\nWinner: bool option }</p>\r\n<p>//Actions\r\nlet getDoorNumber door =\r\nmatch door with\r\n| Door1 -&gt; 0\r\n| Door2 -&gt; 1\r\n| Door3 -&gt; 2</p>\r\n<p>let createGame player : Game =\r\nlet r = rnd 0 3</p>\r\n<pre class=\"fssnip highlighted\"><code lang=\"fsharp\"><span class=\"pn\">{</span> <span class=\"id\">Player</span> <span class=\"o\">=</span> <span class=\"id\">player</span>\r\n  <span class=\"id\">CarLocation</span> <span class=\"o\">=</span> <span class=\"pn\">(</span><span class=\"pn\">[</span> <span class=\"id\">Door1</span><span class=\"pn\">;</span> <span class=\"id\">Door2</span><span class=\"pn\">;</span> <span class=\"id\">Door3</span> <span class=\"pn\">]</span><span class=\"pn\">[</span><span class=\"id\">r</span><span class=\"pn\">]</span><span class=\"pn\">)</span>\r\n  <span class=\"id\">PlayersFirstChoice</span> <span class=\"o\">=</span> <span onmouseout=\"hideTip(event, '3', 3)\" onmouseover=\"showTip(event, '3', 3)\" class=\"id\">None</span>\r\n  <span class=\"id\">MontyRevealed</span> <span class=\"o\">=</span> <span onmouseout=\"hideTip(event, '3', 4)\" onmouseover=\"showTip(event, '3', 4)\" class=\"id\">None</span>\r\n  <span class=\"id\">PlayersFinalChoice</span> <span class=\"o\">=</span> <span onmouseout=\"hideTip(event, '3', 5)\" onmouseover=\"showTip(event, '3', 5)\" class=\"id\">None</span>\r\n  <span class=\"id\">Winner</span> <span class=\"o\">=</span> <span onmouseout=\"hideTip(event, '3', 6)\" onmouseover=\"showTip(event, '3', 6)\" class=\"id\">None</span> <span class=\"pn\">}</span>\r\n</code></pre>\r\n<p>let makeFirstChoice (game: Game) : Game =\r\nlet r = rnd 0 3</p>\r\n<pre class=\"fssnip highlighted\"><code lang=\"fsharp\"><span class=\"pn\">{</span> <span class=\"id\">game</span> <span class=\"k\">with</span>\r\n    <span class=\"id\">PlayersFirstChoice</span> <span class=\"o\">=</span> <span onmouseout=\"hideTip(event, '4', 7)\" onmouseover=\"showTip(event, '4', 7)\" class=\"id\">Some</span><span class=\"pn\">(</span><span class=\"pn\">[</span> <span class=\"id\">Door1</span><span class=\"pn\">;</span> <span class=\"id\">Door2</span><span class=\"pn\">;</span> <span class=\"id\">Door3</span> <span class=\"pn\">]</span><span class=\"pn\">[</span><span class=\"id\">r</span><span class=\"pn\">]</span><span class=\"pn\">)</span> <span class=\"pn\">}</span>\r\n</code></pre>\r\n<p>let montyRevealsDoor (game: Game) : Game =\r\nlet chosenDoor = getDoorNumber game.PlayersFirstChoice.Value\r\nlet carDoor = getDoorNumber game.CarLocation\r\nlet r = rndExclude 0 3 [ chosenDoor; carDoor ]</p>\r\n<pre class=\"fssnip highlighted\"><code lang=\"fsharp\"><span class=\"pn\">{</span> <span class=\"id\">game</span> <span class=\"k\">with</span>\r\n    <span class=\"id\">MontyRevealed</span> <span class=\"o\">=</span> <span onmouseout=\"hideTip(event, '4', 8)\" onmouseover=\"showTip(event, '4', 8)\" class=\"id\">Some</span><span class=\"pn\">(</span><span class=\"pn\">[</span> <span class=\"id\">Door1</span><span class=\"pn\">;</span> <span class=\"id\">Door2</span><span class=\"pn\">;</span> <span class=\"id\">Door3</span> <span class=\"pn\">]</span><span class=\"pn\">[</span><span class=\"id\">r</span><span class=\"pn\">]</span><span class=\"pn\">)</span> <span class=\"pn\">}</span>\r\n</code></pre>\r\n<p>let decideToSwitch game : Game =\r\nmatch game.Player with\r\n| Switcher -&gt;\r\nlet montyRevealed = getDoorNumber game.MontyRevealed.Value\r\nlet playersFirstChoice = getDoorNumber game.PlayersFirstChoice.Value\r\nlet r = rndExclude 0 3 [ montyRevealed; playersFirstChoice ]</p>\r\n<pre class=\"fssnip highlighted\"><code lang=\"fsharp\">    <span class=\"pn\">{</span> <span class=\"id\">game</span> <span class=\"k\">with</span>\r\n        <span class=\"id\">PlayersFinalChoice</span> <span class=\"o\">=</span> <span onmouseout=\"hideTip(event, '4', 9)\" onmouseover=\"showTip(event, '4', 9)\" class=\"id\">Some</span><span class=\"pn\">(</span><span class=\"pn\">[</span> <span class=\"id\">Door1</span><span class=\"pn\">;</span> <span class=\"id\">Door2</span><span class=\"pn\">;</span> <span class=\"id\">Door3</span> <span class=\"pn\">]</span><span class=\"pn\">[</span><span class=\"id\">r</span><span class=\"pn\">]</span><span class=\"pn\">)</span> <span class=\"pn\">}</span>\r\n<span class=\"pn\">|</span> <span class=\"id\">NonSwitcher</span> <span class=\"k\">-&gt;</span>\r\n    <span class=\"pn\">{</span> <span class=\"id\">game</span> <span class=\"k\">with</span>\r\n        <span class=\"id\">PlayersFinalChoice</span> <span class=\"o\">=</span> <span class=\"id\">game</span><span class=\"pn\">.</span><span class=\"id\">PlayersFirstChoice</span> <span class=\"pn\">}</span>\r\n</code></pre>\r\n<p>let isWinner (game: Game) =\r\n{ game with\r\nWinner = Some(game.CarLocation = game.PlayersFinalChoice.Value) }</p>\r\n<p>let play player =\r\ncreateGame player\r\n|&gt; makeFirstChoice\r\n|&gt; montyRevealsDoor\r\n|&gt; decideToSwitch\r\n|&gt; isWinner</p>\r\n<p>let games = 10000</p>\r\n<p>let results =\r\n[ 0..games ]\r\n|&gt; List.map (fun i -&gt; if (i % 2 = 0) then Switcher else NonSwitcher)\r\n|&gt; List.map play\r\n|&gt; List.filter (fun g -&gt; g.Winner.Value)\r\n|&gt; List.countBy (fun g -&gt; (g.Player = Switcher))</p>\r\n<p>let switchers = results |&gt; List.find fst |&gt; snd\r\nlet nonSwitchers = results |&gt; List.find (fun (s, w) -&gt; s = false) |&gt; snd</p>\r\n<p>Chart.Column(\r\nvalues = [ float switchers / float (games / 2); float nonSwitchers / float (games / 2) ],\r\nKeys = [ \"Switchers\"; \"Non Switchers\" ]\r\n)</p>\r\n<p>So how can we explain this using a Bayesian approach. As we saw with the coin example, we think of the car being behind each door as distinct hypotheses. Hypothesis 1 is 'car is behind door 1', Hypothesis 2 is the 'car is behind door 2', Hypothesis 3 the 'car is behind door 3'. The probability of the car being behind each door at the start of the game is 0.33. And lets say we chose door 1 as our first choice.</p>\r\n<p>To summarise</p>\r\n<p>Hypothesis\tProbability\tFirst Choice\r\n| H1 | 0.33 | X | H2 | 0.33 | | H3 | 0.33 |</p>\r\n<p>Monty has to open a door and he selects door 3. Now comes the key step in all applications of Bayes rule, we update the probabilities of the competing Hypotheses based on the data. In this case the data is that Monty selected door 3. The likelihood that he would have selected door 3 is actually different for each hypothesis.</p>\r\n<p>For Hypothesis one, Monty wont open the door that we have chosen so he is left with a choice of doors 2 and 3. So, for H1, there is a 50/50 chance of him opening door 3. However, for H2 there is a 100% chance that Monty opens door 3. He wont open the door you have chosen, door 1, or the door that the car is behind, door 2 in this hypothesis, so he has to open door 3. Lastly there is 0% chance of the car being behind door 3 as he opened this one and he wont open the door that the car is behind it.</p>\r\n<p>So, after Monty opens door three we have the following updated table.</p>\r\n<p>Hypothesis\tProbability\tFirst Choice\tLikelihood of opening door 3\r\nH1\t0.33\tX\t0.5\r\nH2\t0.33\t\t1\r\nH3\t0.33\t\t0\r\nFirst application of Bayes rule in F#\r\nBayes rule tells us to simply multiply the initial probability known as the 'Prior' by the likelihood of the hypothesis given the new data. This gives a new probability known as the 'unormalised Posterior'. We then normalise the Posteriors to give their relative chance. A rough F# implementation would be look as follows.</p>\r\n<p>open System</p>\r\n<p>type Prior =\r\n{ Hypothesis: string\r\nPrior: float\r\nLikelihood: float }</p>\r\n<p>type Posterior =\r\n{ Hypothesis: string\r\nPrior: float\r\nLikelihood: float\r\nPosterior: float }</p>\r\n<p>let calcPosteriors (priors: Prior list) : Posterior list =\r\nlet totalProbability = priors |&gt; List.sumBy (fun r -&gt; r.Prior * r.Likelihood)</p>\r\n<pre class=\"fssnip highlighted\"><code lang=\"fsharp\"><span class=\"id\">priors</span>\r\n<span class=\"o\">|&gt;</span> <span onmouseout=\"hideTip(event, '1', 10)\" onmouseover=\"showTip(event, '1', 10)\" class=\"id\">List</span><span class=\"pn\">.</span><span onmouseout=\"hideTip(event, '5', 11)\" onmouseover=\"showTip(event, '5', 11)\" class=\"id\">map</span> <span class=\"pn\">(</span><span class=\"k\">fun</span> <span class=\"id\">h</span> <span class=\"k\">-&gt;</span>\r\n    <span class=\"pn\">{</span> <span class=\"id\">Hypothesis</span> <span class=\"o\">=</span> <span class=\"id\">h</span><span class=\"pn\">.</span><span class=\"id\">Hypothesis</span>\r\n      <span class=\"id\">Prior</span> <span class=\"o\">=</span> <span class=\"id\">h</span><span class=\"pn\">.</span><span class=\"id\">Prior</span>\r\n      <span class=\"id\">Likelihood</span> <span class=\"o\">=</span> <span class=\"id\">h</span><span class=\"pn\">.</span><span class=\"id\">Likelihood</span>\r\n      <span class=\"id\">Posterior</span> <span class=\"o\">=</span> <span class=\"pn\">(</span><span class=\"pn\">(</span><span class=\"id\">h</span><span class=\"pn\">.</span><span class=\"id\">Prior</span> <span class=\"pn\">*</span> <span class=\"id\">h</span><span class=\"pn\">.</span><span class=\"id\">Likelihood</span><span class=\"pn\">)</span> <span class=\"o\">/</span> <span class=\"id\">totalProbability</span><span class=\"pn\">)</span> <span class=\"pn\">}</span><span class=\"pn\">)</span>\r\n</code></pre>\r\n<p>let montyPriors =\r\n[\r\n{ Hypothesis = \"H1\"\r\nPrior = 0.3333333333\r\nLikelihood = 0.5\r\n}\r\n{ Hypothesis = \"H2\"\r\nPrior = 0.3333333333\r\nLikelihood = 1 }\r\n{ Hypothesis = \"H3\"\r\nPrior = 0.3333333333\r\nLikelihood = 0\r\n} ]</p>\r\n<p>let montyPosteriors =  montyPriors |&gt; calcPosteriors</p>\r\n<p>let rds (n: float)=\r\nMath.Round (n,3) |&gt; string</p>\r\n<p>Chart.Table(\r\nheaderValues = [\"<b>Hypothesis</b>\"; \"<b>Probability</b>\";\"<b>Likelihood of opening door 3</b>\"; \"<b>Posterior</b>\"],\r\ncellsValues = (montyPosteriors |&gt; List.map( fun p -&gt; [p.Hypothesis; rds p.Prior; rds p.Likelihood; rds p.Posterior]))\r\n)\r\nAs you can see the posterior result matches the results from empirical simulation.</p>\r\n<p>Wrap up\r\nBayesian thinking gives us intuitive and powerful ways to approach probability problems. This article has followed the first couple of chapters of the Think Bayes book which is an excellent resource well worth reading in full.</p>\r\n<p>The next post in this series will look at how Bayes rule can be applied to more complex examples. We will also show how the fsharp.stats library can help compose and solve these problems with remarkable efficiency.</p>\r\n<div class=\"fsdocs-tip\" id=\"1\">Multiple items<br />module List\n\nfrom Microsoft.FSharp.Collections<br /><br />--------------------<br />type List&lt;&#39;T&gt; =\n  | op_Nil\n  | op_ColonColon of Head: &#39;T * Tail: &#39;T list\n  interface IReadOnlyList&lt;&#39;T&gt;\n  interface IReadOnlyCollection&lt;&#39;T&gt;\n  interface IEnumerable\n  interface IEnumerable&lt;&#39;T&gt;\n  member GetReverseIndex: rank: int * offset: int -&gt; int\n  member GetSlice: startIndex: int option * endIndex: int option -&gt; &#39;T list\n  static member Cons: head: &#39;T * tail: &#39;T list -&gt; &#39;T list\n  member Head: &#39;T\n  member IsEmpty: bool\n  member Item: index: int -&gt; &#39;T with get\n  ...</div>\r\n<div class=\"fsdocs-tip\" id=\"2\">val contains: value: &#39;T -&gt; source: &#39;T list -&gt; bool (requires equality)</div>\r\n<div class=\"fsdocs-tip\" id=\"3\">union case Option.None: Option&lt;&#39;T&gt;</div>\r\n<div class=\"fsdocs-tip\" id=\"4\">union case Option.Some: Value: &#39;T -&gt; Option&lt;&#39;T&gt;</div>\r\n<div class=\"fsdocs-tip\" id=\"5\">val map: mapping: (&#39;T -&gt; &#39;U) -&gt; list: &#39;T list -&gt; &#39;U list</div>\r\n\r\n",
      "Tags": [
        "Bayes",
        "H&C",
        "F#",
        "Data Science"
      ],
      "Category": "Note",
      "Updated": "2023-09-29T00:00:00.0000000",
      "Created": "2023-09-29T00:00:00.0000000"
    },
    {
      "FileName": "PhysicalOffice",
      "Title": "Why you still need a physical office with a distributed work model",
      "Summary": "Distributed agile working is at the core of Hack and Craft. And now coronavirus has forced most companies into remote working, its benefits are becoming clear even to the most traditional businesses.",
      "Content": "\r\n<p><img src=\"/HandCRed.png\" alt=\"H&amp;C Sign\" /></p>\r\n<p>Reliance on a physical office presence as a way of monitoring productivity is counter-productive as it undermines the intrinsic motivation necessary for high quality creative or intellectual work. Given H&amp;C’s success with remote working, the fact we opened a new office recently may seem counterproductive. Here’s why we did.</p>\r\n<h1>Why does a distributed company need a physical office?</h1>\r\n<p>Our experience of distributed working showed some limitations that can be addressed by a specifically designed physical office. As H&amp;C has grown and evolved we have begun to see the need for a physical space in a different way. We don’t need a shared space for people to collaborate on day-to-day tasks — we’ve been doing this using video conferencing for years.</p>\r\n<p>We needed a physical office for more subtle reasons, which roughly fall in four different areas:</p>\r\n<h2>1. A shared space fosters company culture</h2>\r\n<p>Shared spaces still have a role to play in a distributed company, particularly in transmitting its culture. Through face-to-face contact, trust and rapport can be built with colleagues and clients. A physical space also gives the team a place to work away from their home.</p>\r\n<p>Interestingly, we see marked variation in different people’s willingness to work from home for extended periods, which appears to correlate with their job function. Engineers, who tend to be energised by quiet study and problem solving remain productive and energetic at home. Those in more client facing roles, such as sales and account management, often derive energy from social interactions and therefore need face-to-face contact more often.</p>\r\n<p>A physical shared space is also important for new hires. We need a short, intensive workshop for new team members, and this works much better in our own space. The culture that is absorbed and reflected in our office space binds the team together in resilient working relationships based on shared purpose and values.</p>\r\n<h2>2. Strategising and on-site testing</h2>\r\n<p>At H&amp;C we also need a physical space to develop and test automation technology and <a href=\"https://hackandcraft.com/clients/rs-components-connectpoint/\">IoT platforms</a>, which we deploy in industrial environments. We also find face-to-face contact works better for strategic open-ended discussions, particularly when a less goal orientated conversation is needed to unearth new ideas. Video conferencing works better for every day tactical conversations where concrete decisions must be made quickly.</p>\r\n<h2>3. Maintaining a flow state</h2>\r\n<p>Paradoxically, we needed to create an office that would recreate the ‘working from home’ environment. We’ve observed that single person offices, like those people have at home, result in better quality work. People can reduce interruptions and noise, and spend more time in the flow state that is essential to producing high quality work. <a href=\"https://books.google.co.uk/books?id=TVQUAAAAQBAJ&amp;pg=PA43&amp;lpg=PA43&amp;dq=coding+wars+productivity+factors&amp;source=bl&amp;ots=O_P7dEme1Y&amp;sig=ACfU3U0WW-iMkm1OMe67mG7l6hdbc5S1wg&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiBy_L-7vvoAhV6SxUIHXU6BdQQ6AEwAXoECCcQAQ#v=onepage&amp;q=coding%20wars%20productivity%20factors&amp;f=false\">Studies</a> show that in physical offices there is a direct correlation between people density, which is a proxy for noise and interruptions, and the number of bugs written by those working in the space.</p>\r\n<p>Our operational processes and communication work best when each person has their own mic and camera. At the same time we all access shared documents, in which notes are taken in real time. In terms of office space, we therefore needed a combination of event space, meeting space, social space, and single person offices. The latter must be sufficiently sound proof to prevent echo, even if people in neighbouring offices were dialled into the same meeting. The single person offices must also be large enough for people to work in them all day without claustrophobia. The tiny cubicles often found in coworking spaces are much too small for anything other than short calls.</p>\r\n<h2>4. Building trust with clients</h2>\r\n<p>One of our biggest challenges while working completely remotely is that prospective clients can be deterred if they can’t see the company in its physical form. Acquiring new clients is a process of building trust and a shared understanding of what’s important. This is extremely difficult without face-to-face meetings. And while it’s possible to rent serviceable meeting spaces, these cannot adequately project the dynamism of our company culture. Our new office allows us to invite clients to see how we work, find out more about the team and understand who we are.</p>\r\n<p>For these reasons ‘Lab’ is a more appropriate name than ‘office’ for what we needed.</p>\r\n<h1>How we selected the new H&amp;C Lab— location, location, location</h1>\r\n<p>We took our time selecting the best location for H&amp;C’s new lab and chose <a href=\"http://www.newenglandhouse.org.uk/\">New England House</a> in Brighton, UK. Access to natural light thanks to huge windows, along with a view towards the sea helped clinch the decision.</p>\r\n<p>Brighton has exceptional transport links, with a 35 minute train journey to Gatwick Airport and an hour to London. There is also an emerging tech scene in the city, known as Silicon Beach, as well as the nearby Sussex University with its global reputation for AI and Data Science.</p>\r\n<p>Built in 1962, New England House was part of the brutalist movement and its iconic design encompasses eight floors built entirely from concrete, glass and aluminum. This industrial and functional aesthetic feels like home for H&amp;C, as we work primarily with the industrial sector.</p>\r\n<p>It’s also great to be in the company of other bootstrapped start-ups and entrepreneurs. The building is a hub for a diverse and determined group of entrepreneurs and makers, the calibre of which far exceeds anything I’ve come across within the cushier government and venture capital backed innovation schemes.</p>\r\n<h1>How we designed the space</h1>\r\n<p><img src=\"/OfficeDesign.png\" alt=\"H&amp;C Office Design\" /></p>\r\n<p>When we took over the space it clearly hadn’t been renovated for many decades. It was resplendent with all the trappings of a 1970s attempt at a plush office. Think fake Parquet flooring, endless carpeting, false ceilings, strip lighting and thousands of sockets and network ports.</p>\r\n<p>We decided to strip this all away and return the space to its original aesthetic. This turned out to be a big job. Beneath the carpet we uncovered the original concrete floor which, now polished, works as a stylish and durable surface. It also helps reflect the light, giving the space an open and energetic atmosphere.</p>\r\n<p>The internal partitions would be almost entirely glass so that the light could flood into the central social spaces and reflect on the floor.</p>\r\n<p>Floor sorted, we then erected the stud walls with extra thick plasterboard and internal insulation for soundproofing. A major concern was regulating the temperature of the space, as its large dual aspect windows are single-glazed and a sun trap. We replaced the ancient gas boiler and radiators with air conditioning.</p>\r\n<p><img src=\"/OfficeRenovation.png\" alt=\"H&amp;C Office Renovation\" /></p>\r\n<h1>How we decorated the new H&amp;C Lab</h1>\r\n<p>Simple, durable materials with a feeling of permanence complement the concrete and glass. We salvaged key pieces, such as a large piece of elm sourced from our neighbouring <a href=\"https://www.woodrecycling.org.uk/\">wood recycler</a>. This beautiful piece of wood now serves as a bar where we gather over coffee. They also built our meeting room table from old timbers recovered from Edwardian and Victorian house demolitions. These timeless wood structures sit well among the concrete and glass.</p>\r\n<p>Finally we needed signage. We wanted something that would bring together the industrial and technological aspects of our business. H&amp;C is unlike many digital agencies in that our work deploys technology directly into the real world. Most of the users who encounter the systems we build do so as part of their jobs, which are typically in industrial, manufacturing or supply chain settings. After laser cutting our logo from mild steel, we created a smart sign fitted with leds and a small web server, allowing us to create simple light animations.</p>\r\n<h1>Creating a space that allows us to evolve</h1>\r\n<p>We try to practise what we preach and in relation to physical office design, I think the inhabitants of the office should be constantly evolving the space to work for us. People can move into the Lab when they need to and can fade into working remotely when it suits. This flexibility of form and function is key for our distributed working approach.</p>\r\n<p>Being 100% remote has worked well for H&amp;C since 2014, but as the company has evolved, so has our understanding of what could work better. This melding of remote working and a specifically curated office space designed to harmonise with a distributed agile approach is innovative and scalable. It also feels like home.</p>\r\n<p><img src=\"/JakaSign.jpg\" alt=\"Jaka Sign Installation\" /></p>\r\n<h1>The finished article</h1>\r\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XyeN0LPRe84?si=nbx9I6KylJOxOchU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\r\n\r\n",
      "Tags": [
        "Remote Working",
        "Software Engineering",
        "Teams"
      ],
      "Category": "Essay",
      "Updated": "2020-04-22T00:00:00.0000000",
      "Created": "2020-04-22T00:00:00.0000000"
    },
    {
      "FileName": "QualityControl",
      "Title": "How Quality Control processes can undermine quality",
      "Summary": "Software must now evolve faster than ever. Underlying technology such as cloud infrastructure, operating systems and programming languages now receive near continuous updates from Google, Microsoft, Amazon, and the open source community.",
      "Content": "\r\n<p>Competition between software providers has intensified. Increasing customer expectations require companies to rapidly ‘test and learn’ to find and maintain their markets. Most critically, the security landscape is generating serious new threats almost weekly that previously would occur monthly or annually.</p>\r\n<p>Many organisations, particularly in regulated industries, rely on release processes that were originally designed to maintain quality when the pace of the change was slower. As the need for updates speeds up, some have reached a tipping point and can no longer keep up. Their backlog of critical fixes expands exponentially and the release speed slows in unison.</p>\r\n<hr />\r\n<p>At H&amp;C, we know that maintaining software through regular small updates is easier than large staged releases. Staged releases contain many simultaneous updates, which cause interdependencies that multiply the complexity.</p>\r\n<p>Engineering managers in large organisations are understandably risk averse. They rightly place the burden of proof on the claim that leaner quality control processes are essential for creating quality. This article attempts to provde that proof and suggest how we can begin to design more effective quality control processes.</p>\r\n<p><img src=\"/Sisyphus.jpg\" alt=\"Sisyphus\" /></p>\r\n<h2>Why systems are unstable</h2>\r\n<p>Systems are a union of form and context.[1] As context is constantly evolving, complex systems can never be stable. The ‘form’ of a system refers to its set of formal rules and features. In a software system, this could be the business logic, user experience, interface design or algorithms. The ‘context’ refers to all factors that the form must interact with. In a software system, this includes the cloud environment, user requirements, technical proficiency of the user, connection speeds, current security threats and competitor products.</p>\r\n<p>The quality of a software system is a measure of the closeness of the fit between the form and its surrounding context. The challenge all systems face is the constant evolution of the context. In recent years the pace of this evolution has accelerated.</p>\r\n<p>These changes in context lead to misfits with the form. System maintenance must identify and patch these misfits so that the form evolves in tandem with the context. Due to the constantly evolving nature of the context this amounts to a Sisyphean game of ‘whack-a-mole’.</p>\r\n<h2>Complexity does not increase linearly</h2>\r\n<p>The effort required to resolve these misfits does not increase linearly with each new misfit. The interdependence between misfits in different areas of any system multiplies its complexity. Even if that interdependence is not strictly formal, the practical human effort to make multiple simultaneous changes to a system increases exponentially with the number of changes that need to be made.</p>\r\n<p>Many developments within software engineering such as the single responsibility principle (SRP) and Microservice Architecture are designed to address this problem. The hope is that breaking the system down into small independent parts will prevent complexity buildups as misfits remain local to an individual component. However, microservices are subsystems that, by definition, have complex interdependencies, which require careful planning and simultaneous updates.</p>\r\n<p><img src=\"/SystemDebtDiagrams.png\" alt=\"ComplexityandLinkages\" /></p>\r\n<p>Figures 1-3 show the complexity increasing as the number of misfits and corresponding fixes increase. Each box represents a version of the system, similar to a code branch containing a fix for a specific misfit. A is the current production system and the other boxes are discrete versions.</p>\r\n<p>Simultaneous changes (these are necessary if the number of misfits increase), create exponential complexity as every branch must be compatible with every other. This is in contrast to Figure 4 in which the changes are made fast enough to avoid a build up and can therefore be made linearly.</p>\r\n<p>The cognitive load of addressing the complexity is a factor of the number of links in the release. The links are depicted as double ended arrows. Figure 3 has ten links between the components, while Figure 4 has just four. This can be formalised as C = L², where C is complexity and L is the number of links.</p>\r\n<p>The relationship between complexity and interdepency in simultaneous updates creates the phenomenon that a linear rewrite of a system from scratch is often simpler than patching an existing system. This fact leads to difficult conversations between engineers and their managers who seldom understand the practical implications of this type of complexity.</p>\r\n<h2>Release cycles must keep pace with context changes to prevent a build up in complexity</h2>\r\n<p><img src=\"/MisfitGraphs.png\" alt=\"Release cycle\" /></p>\r\n<p>Figure 5 shows the different stages in a release cycle of a system. The length of 'Time to Live' is fixed by the organisation’s internal processes. Each stage contributes to the Time to Live, but in organisations that are struggling with quality issues, the ‘Fix Validated’ stage tends to increase.</p>\r\n<p>As release cycles lengthen they also become less elastic. This means the Time to Live takes approximately the same amount of time regardless of the scale of the fix currently being pushed through.</p>\r\n<p>The other pivotal interval in the diagram is the Misfit Frequency. This is the time between each context update that goes on to create a new misfit to be addressed. To prevent the build up in complexity, the Time to Live must be shorter than the Misfit Frequency.</p>\r\n<p>Misfit Frequency will vary widely from system to system. The printing presses changed very slowly until the information age. Now every blog platform must regularly and reactively release fixes for new versions of the major browsers.</p>\r\n<p>This step change in the evolution speed of context presents serious challenges to transforming organisations. Those that are moving from the relatively slow moving hardware medium to the more rapid software medium - or from installable software to the cloud - find their release processes are too slow to keep up with the context evolution and resulting misfit frequency. This leads to a build up of complexity that quickly swamps the organisation and erodes the quality of their systems.</p>\r\n<h2>Expanding Quality Control processes is counter productive if the release cycle becomes too slow</h2>\r\n<p>An understandable reaction from management to seeing poor quality systems go into production is to question why there weren't more checks in place to prevent this happening. This often results in adding yet more layers of checks, rather than fine tuning of the existing ones.</p>\r\n<p>This leads to a proliferation of overlapping quality processes, which slow the speed at which misfits can be resolved. Eventually process overheads reach critical mass, pushing the project into a vicious circle of increasing complexity and bureaucratic paralysis.</p>\r\n<p>Due to the nature of complexity, quality is directly correlated to how fast a system can get a misfit fix into production. Despite this, it is also clear that engineers do make mistakes and that some form of checking prior to production deployment is essential.</p>\r\n<p>Automated testing was developed as a response to the need for rapid large scale testing. In practice some form of manual testing should always be part of the fail safe. However, the utility of the manual process depends on both its accuracy in identifying detects and, crucially, the delay it creates in Time to Live.  (In a future post I will describe the techniques H&amp;C uses to increase quality without lengthening release cycles. In short, they arise from the change of perspective which sees quality as an ongoing process rather than a retrospective spot check. [2] )</p>\r\n<p>The accuracy of any validation stage can be formalised as a probability of detecting a defect if one is present. After a certain threshold of defect detection probability is achieved, any further expansion of validation processes gives diminishing returns, slows the Time to Live, builds up complexity, and thereby decreases quality.</p>\r\n<h2>The quality of a system is determined by the ratio between the time it takes to deploy a fix, and the speed at which the context generates the need for new fixes</h2>\r\n<p>As we have seen, it is essential to avoid the simultaneous changes caused by a build up of unaddressed misfits. We can formulate this understanding of the relationship between quality, validation processes, and the time it takes to get a fix into production as follows:</p>\r\n<p>Quality (Q): The closeness of the fit between form and context.\\\r\nMisfit Frequency (MF): The time interval between each misfit. \\\r\nTime to Live (TTL): TIme interval from discovery of misfit to deployment into production.\\\r\nDefect Detection: The probability (expressed as number between 0 and 1) of the quality control process uncovering a defect in a new release addressing a misfit.</p>\r\n<p>Q = (MF / TTL) * DD</p>\r\n<p>While simplistic, this equation does give insight into the real relationship between these variables and shows how we can begin to optimise for quality. It shows that TTL must be less than MF in order to prevent the build up of misfits and the paralysing complexity that comes with it</p>\r\n<p>Sample calculations could include, where:</p>\r\n<p>TTL = 5 days\\\r\nMF = 8 days\\\r\nDD = 80% chance of spotting defects.</p>\r\n<p>(8/5) * 0.8 = Quality 1.28</p>\r\n<p>Critically, if we adjust these variables slightly to make the Time to Live longer at seven days, almost at a misfit rate, we get a quality score of 1.02.</p>\r\n<p>If the Time to Live exceeds the Misfit Frequency then quality very rapidly deteriorates. For example, where:</p>\r\n<p>TTL = 15 days\\\r\nMF = 8 days\\\r\nDD = 95%</p>\r\n<p>Gives a quality score of 0.5.</p>\r\n<p><img src=\"/QualitybyDefectDetection.png\" alt=\"Quality by Defect Dectection\" /></p>\r\n<p>This graph shows how quality decreases once the Defect Detection probability increases above a certain point. It assumes that each 10% increase in the DD rate adds one unit onto the Time to Live. It illustrates that lengthy release processes cause an exponential increase in complexity which will inevitably lead to a decrease in quality.</p>\r\n<h2>Quality control processes must be lean</h2>\r\n<p>A proper understanding of complexity and its root causes necessitates a release process faster than the rate at which the context evolves. Organisations must be sceptical of any increase in process weight that may obstruct their ability to deploy necessary fixes. The tendency towards process bloat is also self-perpetuating and difficult to reverse.</p>\r\n<p>The context in which all information systems operate is evolving faster than ever. External dependencies such as the cloud are updated on a near daily basis. User expectations of the power and simplicity of technology are also growing exponentially. Systems which are trapped in a vicious circle of bureaucracy and complexity buildups will fall further and further behind.</p>\r\n<p>We must create quality control processes that are as nimble and fast as they are robust and thorough. Indeed, quality control processes should be as concerned with the fixes they don't make as those that they do.</p>\r\n<h5>Notes</h5>\r\n<p>[1] The nature of Form and Context is explored in more detail by Christopher Alexander in his book about Architectural Design <a href=\"https://en.wikipedia.org/wiki/Notes_on_the_Synthesis_of_Form\">‘Notes on the Synthesis of Form.'</a></p>\r\n<p>[2] H&amp;C's approach includes embedding a Secure Development Lifecycle and threat modelling into our sprint cycles. We also use statically typed functional programming languages. Their algebraic type system increases domain model expressiveness and captures many errors at compile time before the code is deployed.</p>\r\n\r\n",
      "Tags": [
        "Agile",
        "H&C",
        "Software Engineering",
        "Quality Control"
      ],
      "Category": "Essay",
      "Updated": "2020-05-16T00:00:00.0000000",
      "Created": "2020-05-16T00:00:00.0000000"
    }
  ]
}